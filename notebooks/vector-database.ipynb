{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Setup and Install Required Libraries\n",
    "# Install necessary libraries if they are not already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pgvector psycopg2 langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Database Connection Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "\n",
    "# Environment variables for PostgreSQL connection\n",
    "POSTGRES_HOST = os.getenv('POSTGRES_HOST', 'localhost')\n",
    "POSTGRES_USER = os.getenv('POSTGRES_USER', 'user')\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD', 'password')\n",
    "POSTGRES_DB = os.getenv('POSTGRES_DB', 'vector_db')\n",
    "\n",
    "# Create a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host=POSTGRES_HOST,\n",
    "    user=POSTGRES_USER,\n",
    "    password=POSTGRES_PASSWORD,\n",
    "    dbname=POSTGRES_DB\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Load and Process Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_store_document(file_path):\n",
    "    \"\"\"\n",
    "    This function processes the document, splits it into chunks, \n",
    "    generates embeddings, and stores them in the PostgreSQL database.\n",
    "    \"\"\"\n",
    "    # Initialize the document loader for PDF (adjust this for other formats)\n",
    "    loader = PyPDFLoader(file_path)\n",
    "\n",
    "    # Split the document into smaller chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    documents = loader.load_and_split(text_splitter)\n",
    "\n",
    "    # Initialize the OpenAI embeddings model (or use VertexAI if needed)\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "    # Initialize PGVector with connection details\n",
    "    vector_search = PGVector(\n",
    "        collection_name='documents', \n",
    "        connection_string=f'postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}/{POSTGRES_DB}',\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "\n",
    "    # Remove null characters and prepare document content for insertion\n",
    "    for document in documents:\n",
    "        document.page_content = document.page_content.replace('\\x00', '')\n",
    "    \n",
    "    # Store documents in the PostgreSQL vector database\n",
    "    vector_search.add_documents(documents)\n",
    "    \n",
    "    print(f\"{file_path} was successfully processed and embedded.\")\n",
    "    print(f\"Number of document chunks: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Process a Local File and Send it to Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the path to your local document\n",
    "file_path = \"/home/jovyan/work/sample_document.pdf\"  # adjust path if needed\n",
    "\n",
    "process_and_store_document(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Perform a Semantic Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_semantic_search(query_text, top_k=2):\n",
    "    \"\"\"\n",
    "    This function performs a semantic search against the vector database.\n",
    "    It retrieves a maximum of `top_k` results based on similarity to `query_text`.\n",
    "    \"\"\"\n",
    "    # Initialize the embedding model for query embeddings\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "    # Reinitialize PGVector for search\n",
    "    vector_search = PGVector(\n",
    "        collection_name='documents', \n",
    "        connection_string=f'postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}/{POSTGRES_DB}',\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "\n",
    "    # Perform the similarity search on the query text\n",
    "    results = vector_search.similarity_search(query_text, k=top_k)\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Top {top_k} search results for query: '{query_text}'\\n\")\n",
    "    for idx, result in enumerate(results):\n",
    "        print(f\"Result {idx + 1}:\\n\")\n",
    "        print(result.page_content)\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Run a Semantic Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Describe the key points of semantic search in AI.\"\n",
    "\n",
    "# Perform a semantic search with the query text\n",
    "perform_semantic_search(query_text, top_k=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
